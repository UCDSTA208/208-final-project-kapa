{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top 50 words\n",
    "- Calculate times/ number of corrects\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HUI/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import collections \n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, roc_curve\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import collections\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"All_email.txt\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate to training /test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Seperate to training data/test data\n",
    "train, test = train_test_split(data, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18321</td>\n",
       "      <td>29644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ham   spam\n",
       "0  18321  29644"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = collections.Counter()\n",
    "c.update(test['Classification'])\n",
    "pd.DataFrame({'ham': c['ham'],'spam':c['spam']},index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.392410</td>\n",
       "      <td>0.607590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.749098</td>\n",
       "      <td>0.250902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.079104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.668820</td>\n",
       "      <td>0.331180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.235116</td>\n",
       "      <td>0.764884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.955364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.066356</td>\n",
       "      <td>0.933644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.309909</td>\n",
       "      <td>0.690091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.339796</td>\n",
       "      <td>0.660204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ham      spam\n",
       "1999  0.392410  0.607590\n",
       "2000  0.749098  0.250902\n",
       "2001  0.920896  0.079104\n",
       "2002  0.668820  0.331180\n",
       "2003  0.235116  0.764884\n",
       "2004  0.044636  0.955364\n",
       "2005  0.066356  0.933644\n",
       "2006  0.309909  0.690091\n",
       "2007  0.339796  0.660204"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_count = []\n",
    "for i in ['1999','2000','2001','2002','2003','2004','2005','2006','2007']:\n",
    "          c=collections.Counter(data[data['Year']==i]['Classification'])\n",
    "          year_count.append(c)\n",
    "year_count = pd.DataFrame(year_count,index=['1999','2000','2001','2002','2003','2004','2005','2006','2007'])\n",
    "\n",
    "year_rate = pd.DataFrame({'ham' : year_count['ham']/year_count.sum(axis=1),\n",
    "                          'spam' : 1- year_count['ham']/year_count.sum(axis=1)})\n",
    "\n",
    "year_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour_count = []\n",
    "hour  = ['00','01','02','03','04','05','06','07','08','09','10','11',\n",
    "         '12','13','14','15','16','17','18','19','20','21','22','23']\n",
    "for i in hour :\n",
    "          c=collections.Counter(data[data['Hour']==i]['Classification'])\n",
    "          hour_count.append(c)\n",
    "hour_count = pd.DataFrame(hour_count,index=hour)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=[8,8])\n",
    "line1, = plt.plot(hour_count['ham']/sum(hour_count['ham']), label='ham')\n",
    "line2, = plt.plot(hour_count['spam']/sum(hour_count['spam']), label='spam')\n",
    "plt.axvline(x=8,c='gray',linestyle='dashed')\n",
    "plt.axvline(x=16,c='gray',linestyle='dashed')\n",
    "plt.legend()\n",
    "plt.savefig('hour_count.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wd_count = []\n",
    "wd  = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "for i in wd :\n",
    "          c=collections.Counter(data[data['Weekday']==i]['Classification'])\n",
    "          wd_count.append(c)\n",
    "wd_count = pd.DataFrame(wd_count,index=range(7))\n",
    "\n",
    "fig = plt.figure(figsize=[8,8])\n",
    "line1, = plt.plot(wd_count['ham']/sum(wd_count['ham']), label='ham')\n",
    "line2, = plt.plot(wd_count['spam']/sum(wd_count['spam']), label='spam')\n",
    "plt.xticks(range(7),wd)\n",
    "plt.legend()\n",
    "plt.savefig('wd_count.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/inspect.py\", line 500, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/posixpath.py\", line 375, in realpath\n",
      "    path, ok = _joinrealpath('', filename, {})\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/posixpath.py\", line 399, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/posixpath.py\", line 68, in join\n",
      "    if b.startswith('/'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1824\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1406\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1314\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m             )\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HUI/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1196\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 412, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 628, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 651, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 116, in zmq.backend.cython._poll.zmq_poll (zmq/backend/cython/_poll.c:2036)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/_poll.c:2418)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n",
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 412, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 628, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 651, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/Users/HUI/miniconda2/lib/python2.7/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 116, in zmq.backend.cython._poll.zmq_poll (zmq/backend/cython/_poll.c:2036)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/_poll.c:2418)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#tfidf(original,bi,tri)\n",
    "count = CountVectorizer(ngram_range=(1,1),stop_words='english',analyzer='word')\n",
    "count_bi = CountVectorizer(ngram_range=(1,2),stop_words='english',analyzer='word')\n",
    "\n",
    "\n",
    "X_train_counts = count.fit_transform(train['Content'])\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_counts = count.transform(test['Content'])\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "c = collections.Counter()\n",
    "c.update(test['Classification'])\n",
    "pd.DataFrame({'ham': c['ham'],'spam':c['spam']},index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1:spam; 0:ham\n",
    "y_train = train['Classification']\n",
    "y_train  = (y_train  == 'spam')*1\n",
    "y_test = test['Classification']\n",
    "y_test = (y_test  == 'spam')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111916, 6824798)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111916,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 words per \n",
    "\n",
    "- Array problems\n",
    "- Keep run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean=pickle.load(open(\"data_clean.txt\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topwords(n=50,year='1999',data=data_clean,cla='spam'):\n",
    "\tSpam = data[data['Classification']==cla]\n",
    "\tcounts_vec = count.fit_transform(Spam[Spam['Year']==year]['clean_emails'])\n",
    "\tsum_counts = np.array(counts_vec.sum(axis=0))\n",
    "\n",
    "\tfeature_array = np.array(count.get_feature_names())\n",
    "\tcounts_sorting = np.argsort(sum_counts).flatten()[::-1]\n",
    "\ttop_n = feature_array[counts_sorting][:n]\n",
    "\t#np.set_printoptions(threshold='nan')\n",
    "\treturn top_n \n",
    "\n",
    "tw=[]\n",
    "for i in ['1999','2000','2001','2002','2003','2004','2005','2006','2007']:\n",
    "\ttw.append({i:topwords(10,i)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>price</td>\n",
       "      <td>price</td>\n",
       "      <td>free</td>\n",
       "      <td>price</td>\n",
       "      <td>price</td>\n",
       "      <td>company</td>\n",
       "      <td>com</td>\n",
       "      <td>pills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company</td>\n",
       "      <td>company</td>\n",
       "      <td>free</td>\n",
       "      <td>email</td>\n",
       "      <td>company</td>\n",
       "      <td>company</td>\n",
       "      <td>statements</td>\n",
       "      <td>price</td>\n",
       "      <td>desjardins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>info</td>\n",
       "      <td>info</td>\n",
       "      <td>com</td>\n",
       "      <td>click</td>\n",
       "      <td>pills</td>\n",
       "      <td>email</td>\n",
       "      <td>information</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold</td>\n",
       "      <td>gold</td>\n",
       "      <td>company</td>\n",
       "      <td>mail</td>\n",
       "      <td>mg</td>\n",
       "      <td>money</td>\n",
       "      <td>adobe</td>\n",
       "      <td>net</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>adobe</td>\n",
       "      <td>save</td>\n",
       "      <td>money</td>\n",
       "      <td>item</td>\n",
       "      <td>professional</td>\n",
       "      <td>business</td>\n",
       "      <td>org</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adobe</td>\n",
       "      <td>windows</td>\n",
       "      <td>website</td>\n",
       "      <td>business</td>\n",
       "      <td>info</td>\n",
       "      <td>information</td>\n",
       "      <td>com</td>\n",
       "      <td>company</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>windows</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>list</td>\n",
       "      <td>save</td>\n",
       "      <td>com</td>\n",
       "      <td>price</td>\n",
       "      <td>gold</td>\n",
       "      <td>votre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>office</td>\n",
       "      <td>campaign</td>\n",
       "      <td>money</td>\n",
       "      <td>information</td>\n",
       "      <td>gold</td>\n",
       "      <td>new</td>\n",
       "      <td>professional</td>\n",
       "      <td>hotmail</td>\n",
       "      <td>online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>save</td>\n",
       "      <td>hi</td>\n",
       "      <td>like</td>\n",
       "      <td>time</td>\n",
       "      <td>stock</td>\n",
       "      <td>mail</td>\n",
       "      <td>time</td>\n",
       "      <td>info</td>\n",
       "      <td>vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xp</td>\n",
       "      <td>office</td>\n",
       "      <td>adobe</td>\n",
       "      <td>new</td>\n",
       "      <td>click</td>\n",
       "      <td>time</td>\n",
       "      <td>email</td>\n",
       "      <td>aol</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1999       2000       2001         2002     2003          2004  \\\n",
       "0      price      price      price         free    price         price   \n",
       "1    company    company       free        email  company       company   \n",
       "2       info       info        com        click    pills         email   \n",
       "3       gold       gold    company         mail       mg         money   \n",
       "4  microsoft      adobe       save        money     item  professional   \n",
       "5      adobe    windows    website     business     info   information   \n",
       "6    windows  microsoft  microsoft         list     save           com   \n",
       "7     office   campaign      money  information     gold           new   \n",
       "8       save         hi       like         time    stock          mail   \n",
       "9         xp     office      adobe          new    click          time   \n",
       "\n",
       "           2005     2006        2007  \n",
       "0       company      com       pills  \n",
       "1    statements    price  desjardins  \n",
       "2   information    yahoo          mg  \n",
       "3         adobe      net        item  \n",
       "4      business      org       price  \n",
       "5           com  company        save  \n",
       "6         price     gold       votre  \n",
       "7  professional  hotmail      online  \n",
       "8          time     info        vous  \n",
       "9         email      aol        like  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(tw[0]),pd.DataFrame(tw[1]),pd.DataFrame(tw[2]),\n",
    "          pd.DataFrame(tw[3]),pd.DataFrame(tw[4]),pd.DataFrame(tw[5]),\n",
    "          pd.DataFrame(tw[6]),pd.DataFrame(tw[7]),pd.DataFrame(tw[8])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>board</td>\n",
       "      <td>ect</td>\n",
       "      <td>enron</td>\n",
       "      <td>list</td>\n",
       "      <td>dmdx</td>\n",
       "      <td>dmdx</td>\n",
       "      <td>putdup</td>\n",
       "      <td>node</td>\n",
       "      <td>samba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use</td>\n",
       "      <td>enron</td>\n",
       "      <td>company</td>\n",
       "      <td>linux</td>\n",
       "      <td>edu</td>\n",
       "      <td>mail</td>\n",
       "      <td>dmdx</td>\n",
       "      <td>nodes</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hb</td>\n",
       "      <td>hou</td>\n",
       "      <td>said</td>\n",
       "      <td>com</td>\n",
       "      <td>mit</td>\n",
       "      <td>putdup</td>\n",
       "      <td>interval</td>\n",
       "      <td>network</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>handyboard</td>\n",
       "      <td>subject</td>\n",
       "      <td>ect</td>\n",
       "      <td>new</td>\n",
       "      <td>mail</td>\n",
       "      <td>file</td>\n",
       "      <td>edu</td>\n",
       "      <td>time</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>vince</td>\n",
       "      <td>energy</td>\n",
       "      <td>data</td>\n",
       "      <td>cert</td>\n",
       "      <td>use</td>\n",
       "      <td>obj</td>\n",
       "      <td>information</td>\n",
       "      <td>branches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>edu</td>\n",
       "      <td>cc</td>\n",
       "      <td>new</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>jonathan</td>\n",
       "      <td>mail</td>\n",
       "      <td>peer</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thanks</td>\n",
       "      <td>pm</td>\n",
       "      <td>power</td>\n",
       "      <td>like</td>\n",
       "      <td>list</td>\n",
       "      <td>list</td>\n",
       "      <td>list</td>\n",
       "      <td>file</td>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>using</td>\n",
       "      <td>com</td>\n",
       "      <td>subject</td>\n",
       "      <td>time</td>\n",
       "      <td>information</td>\n",
       "      <td>digitalvox</td>\n",
       "      <td>university</td>\n",
       "      <td>new</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>know</td>\n",
       "      <td>thanks</td>\n",
       "      <td>com</td>\n",
       "      <td>net</td>\n",
       "      <td>time</td>\n",
       "      <td>wrote</td>\n",
       "      <td>endobj</td>\n",
       "      <td>message</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time</td>\n",
       "      <td>gas</td>\n",
       "      <td>gas</td>\n",
       "      <td>message</td>\n",
       "      <td>ms</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>mail</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1999     2000     2001     2002         2003        2004        2005  \\\n",
       "0       board      ect    enron     list         dmdx        dmdx      putdup   \n",
       "1         use    enron  company    linux          edu        mail        dmdx   \n",
       "2          hb      hou     said      com          mit      putdup    interval   \n",
       "3  handyboard  subject      ect      new         mail        file         edu   \n",
       "4        like    vince   energy     data         cert         use         obj   \n",
       "5         edu       cc      new      use          use    jonathan        mail   \n",
       "6      thanks       pm    power     like         list        list        list   \n",
       "7       using      com  subject     time  information  digitalvox  university   \n",
       "8        know   thanks      com      net         time       wrote      endobj   \n",
       "9        time      gas      gas  message           ms        time        time   \n",
       "\n",
       "          2006      2007  \n",
       "0         node     samba  \n",
       "1        nodes    source  \n",
       "2      network       new  \n",
       "3         time      help  \n",
       "4  information  branches  \n",
       "5         peer      code  \n",
       "6         file      list  \n",
       "7          new       com  \n",
       "8      message      data  \n",
       "9         mail       use  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw=[]\n",
    "for i in ['1999','2000','2001','2002','2003','2004','2005','2006','2007']:\n",
    "\ttw.append({i:topwords(10,i,cla='ham')})\n",
    "pd.concat([pd.DataFrame(tw[0]),pd.DataFrame(tw[1]),pd.DataFrame(tw[2]),\n",
    "          pd.DataFrame(tw[3]),pd.DataFrame(tw[4]),pd.DataFrame(tw[5]),\n",
    "          pd.DataFrame(tw[6]),pd.DataFrame(tw[7]),pd.DataFrame(tw[8])],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reduction (SVD/LSA)\n",
    "\n",
    "- Reduce Tfidf matrix to dim=100 LSA matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "lsa = TruncatedSVD(100, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(X_train_tf)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n",
    "\n",
    "dtm_lsa_test = lsa.transform(X_test_tf)\n",
    "dtm_lsa_test = Normalizer(copy=False).transform(dtm_lsa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2,figsize=(16,8))\n",
    "colors=['blue','orange']\n",
    "axarr[0].scatter(dtm_lsa[[i for i, x in enumerate(y_train==0) if x],1],\n",
    "                 dtm_lsa[[i for i, x in enumerate(y_train==0) if x],2],\n",
    "                 color = 'blue',label ='ham')\n",
    "\n",
    "axarr[0].scatter(dtm_lsa[[i for i, x in enumerate(y_train==1) if x],1],\n",
    "                 dtm_lsa[[i for i, x in enumerate(y_train==1) if x],2],\n",
    "                 color = 'orange',label ='spam')\n",
    "\n",
    "axarr[0].set_ylabel('Second principal component')\n",
    "axarr[0].set_xlabel('First principal component')\n",
    "axarr[0].legend(loc = 'lower right')\n",
    "axarr[0].set_title('Plot of points against LSA principal component for training data')\n",
    "\n",
    "\n",
    "axarr[1].scatter(dtm_lsa_test[[i for i, x in enumerate(y_test==0) if x],1],\n",
    "                 dtm_lsa_test[[i for i, x in enumerate(y_test==0) if x],2],\n",
    "                 color = 'blue',label ='ham')\n",
    "\n",
    "axarr[1].scatter(dtm_lsa_test[[i for i, x in enumerate(y_test==1) if x],1],\n",
    "                 dtm_lsa_test[[i for i, x in enumerate(y_test==1) if x],2],\n",
    "                 color = 'orange',label ='spam')\n",
    "axarr[1].set_xlabel('First principal component')\n",
    "axarr[1].set_ylabel('Second principal component')\n",
    "axarr[1].set_title('Plot of points against LSA principal component for testing data')\n",
    "axarr[1].legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('data_reduction_cp12.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94583550505576985"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('lsa', TruncatedSVD(100, algorithm = 'arpack',random_state=0)),\n",
    "                     ('clf', LinearSVC(C=1,random_state=0))])\n",
    "_ = text_clf.fit(X_train_tf,y_train)\n",
    "predicted = text_clf.predict(X_test_tf)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16667,   944],\n",
       "       [ 1654, 28700]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBFSVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92246429688314391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('lsa', TruncatedSVD(100, algorithm = 'arpack',random_state=0)),\n",
    "                     ('clf', SVC(C=1,random_state=0))])\n",
    "_ = text_clf.fit(X_train_tf,y_train)\n",
    "predicted = text_clf.predict(X_test_tf)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15303,   701],\n",
       "       [ 3018, 28943]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters = {'clf__C': [0.001,0.01,0.05,0.1,0.2,0.5,0.7,1]}\n",
    "#gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Work on the server tune C = 1\n",
    "# gs_clf = gs_clf.fit(X_train_tf, y_train)\n",
    "# best_parameters = gs_clf.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
