% !TEX root = main.tex

For decision tree, we use cross validation to tune the parameter max\_depth which represent the maximum depth of the tree. The candidate of the parameter is the 10, 20, 50, and the default one which is that the nodes are expanded until all leaves are pure or until all leaves contain less than min\_samples\_split samples. When tuning the model fitting with unit-gram tfidf after data reduction, the average running time for each is around 80 seconds while when max\_depth is 10, the running time would be the shortest. The best parameter is max\_depth=20 with its corresponding accuracy rate 0.9447. The confusion matrix is shown in Table \ref{Confusion_DT}. When the data original is ham email, we will mis-classificated it to be spam email 8.1\% of the time. While when the data is a spam email, we will mis-classificated it to be ham email 3.9367\% of time. This implies that for a ham email, we will have higher probability to have wrong prediction.\\

If right now we change to use bi-gram tfidf to fit the models with the same candidate of parameters, the time for fitting a model will be much longer than fitting unit-gram. It's around 1300 seconds to fit a model. The best parameter here is also max\_depth = 20. The accuracy rate here is 0.9398, which is smaller than that of one-gram model with max\_depth = 20. The confusion matrix is shown in Table \ref{Confusion_DT}. The mis-classification rate when the data is ham will be 8.3729\% and that for a spam email is 4.5641\%. The ham email will also have higher probability to predict wrong. 



